import cv2
import numpy as np
import mediapipe as mp
import time
import os

mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose
mp_holistic = mp.solutions.holistic

# Video Capture
capture = cv2.VideoCapture(0)

# Grayscale for haar cascade
# gray = cv2.cvtColor(capture,cv2.COLOR_BGR2GRAY)

fgbg = cv2.createBackgroundSubtractorMOG2(50, 200, True)

#Fall detected or not
fall=False
FallDetected = False

# Keeps track of what frame we're on
frameCount = 0

# Create haar cascade
haar_cascade = cv2.CascadeClassifier('haar_face.xml')

# faces_rect = haar_cascade.detectMultiScale(gray,scaleFactor=1.1, minNeighbors=3)

prevTime = 0
with mp_pose.Pose(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as pose:
    while (1):
        # Return Value and the current frame
        ret, frame = capture.read()

        # Recoloring
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame.flags.writeable = False

        # Make Detection
        results = pose.process(frame)

        # Color to BGR
        frame.flags.writeable = True
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)



        # Get Landmarks
        try:
            if frameCount > 1 & frameCount % 5 == 0:
                oldnose = nose
                oldleftshoulder = left_shoulder
                oldrightshoulder = right_shoulder
                oldlefthip = left_hip
                oldrighthip = right_hip

            landmarks = results.pose_landmarks.landmark
            # print(landmarks[mp_pose.PoseLandmark.NOSE.value].y )
            # Defining Landmarks
            nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].y]
            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]

           # if frameCount % 2 == 0:
            #    while fall != True:
             #   if nose-oldnose > 0.1 :

            if frameCount>1 and frameCount % 2 == 0:
                if nose > oldrighthip and nose >oldlefthip:
                    fall = True
                    check = frameCount

            if frameCount != 0 and frameCount + 5 == check:
                FallDetected = True

            if FallDetected:
                print ("Fall Detected")

            #check all if they dropped, then if true check for the next 5 seconds to see if the y level of old log goes to normal. if yes its not a fall if no its a fall



        except:
            pass



        #if frameCount > 1:
         #  left_shoulderlog[frameCount] = left_shoulder
          #  right_shoulderlog[frameCount] = right_shoulder
           # left_hiplog[frameCount] = left_hip
            #right_hiplog[frameCount] = right_hip
            #if frameCount % 5 == 0:
             #   if movement == True:
              #      HasMovement = True
               # else:
                #    HasMovement = False





        mp_drawing.draw_landmarks(
            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        currTime = time.time()
        fps = 1 / (currTime - prevTime)
        prevTime = currTime

        if frameCount > 5:
            print(nose , 'nose')
            print(left_shoulder , 'left shoulder')
            print(right_shoulder , 'right shoulder')
            print(left_hip , 'left hip')
            print(right_hip , 'right hip')
        # Draw rectangle over face
        for (x, y, w, h) in faces_rect:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), thickness=2)

        #  Check if a current frame actually exist
        if not ret:
            break

        frameCount += 1
        # Resize the frame
        resizedFrame = cv2.resize(frame, (1280, 720), fx=0.50, fy=0.50)

        # Get the foreground mask
        fgmask = fgbg.apply(resizedFrame)

        # Count all the non zero pixels within the mask
        count = np.count_nonzero(fgmask)

        print('Frame: %d, Pixel Count: %d' % (frameCount, count))

        # Determine how many pixels do you want to detect to be considered "movement"
        if frameCount > 1 and count > 2500:
            movement = True
            print("Movement Detected")
            cv2.putText(resizedFrame, 'Movement Detected', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,
                        cv2.LINE_AA)

        gray = cv2.cvtColor(resizedFrame, cv2.COLOR_BGR2GRAY)
        faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)

        # Draw rectangle over face
        for (x, y, w, h) in faces_rect:
            cv2.rectangle(resizedFrame, (x, y), (x + w, y + h), (0, 0, 255), thickness=2)
            cv2.putText(resizedFrame, 'Face Detected', (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,
                        cv2.LINE_AA)

        cv2.putText(resizedFrame, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 196, 255), 2)
        cv2.imshow("Camera", resizedFrame)


        k = cv2.waitKey(1) & 0xff
        if k == 27:
            break

capture.release()
cv2.destroyAllWindows()
