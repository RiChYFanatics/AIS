import cv2
import numpy as np
import mediapipe as mp
import time
import os
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose
mp_holistic = mp.solutions.holistic


# Video Capture
capture = cv2.VideoCapture(0)

#Grayscale for haar cascade
#gray = cv2.cvtColor(capture,cv2.COLOR_BGR2GRAY)

fgbg = cv2.createBackgroundSubtractorMOG2(50, 200, True)

# Keeps track of what frame we're on
frameCount = 0

#Create haar cascade
haar_cascade = cv2.CascadeClassifier('haar_face.xml')

#faces_rect = haar_cascade.detectMultiScale(gray,scaleFactor=1.1, minNeighbors=3)

prevTime = 0
with mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5) as pose:
	while(1):
		# Return Value and the current frame
		ret, frame = capture.read()

		#Recoloring
		gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
		faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)

		frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
		frame.flags.writeable = False

		#Make Detection
		results = pose.process(frame)

		#Color to BGR
		frame.flags.writeable = True
		frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

		#Get Landmarks
		try:
			landmarks = results.pose_landmarks.landmark
			#print(landmarks[mp_pose.PoseLandmark.NOSE.value].y )

		except:
			pass

		#Defining Landmarks
		nose = [landmarks[mp_pose.PoseLandmark.NOSE.value].y]
		left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
		right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
		left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
		right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
		print (left_hip,right_hip,left_shoulder,right_shoulder,nose)



		mp_drawing.draw_landmarks(
			frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
		currTime = time.time()
		fps = 1 / (currTime - prevTime)
		prevTime = currTime

		#Draw rectangle over face
		for (x,y,w,h) in faces_rect:
			cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), thickness=2 )

		#  Check if a current frame actually exist
		if not ret:
			break

		frameCount += 1
		# Resize the frame
		resizedFrame = cv2.resize(frame, (0, 0), fx=0.50, fy=0.50)

		# Get the foreground mask
		fgmask = fgbg.apply(resizedFrame)

		# Count all the non zero pixels within the mask
		count = np.count_nonzero(fgmask)

		print('Frame: %d, Pixel Count: %d' % (frameCount, count))

		# Determine how many pixels do you want to detect to be considered "movement"
		if frameCount > 1 and count > 500:
			movement = True
			print("Movement Detected")
			cv2.putText(resizedFrame, 'Movement Detected', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)


		gray = cv2.cvtColor(resizedFrame, cv2.COLOR_BGR2GRAY)
		faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)

		#Draw rectangle over face
		for (x,y,w,h) in faces_rect:
			cv2.rectangle(resizedFrame, (x,y), (x+w,y+h), (0,0,255), thickness=2 )
			cv2.putText(resizedFrame, 'Face Detected', (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,
						cv2.LINE_AA)

		cv2.putText(resizedFrame, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 196, 255), 2)
		cv2.imshow("Camera", resizedFrame )


		k = cv2.waitKey(1) & 0xff
		if k == 27:
			break

capture.release()
cv2.destroyAllWindows()
